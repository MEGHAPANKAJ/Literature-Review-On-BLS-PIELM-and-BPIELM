{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZhMCgLLgiHa"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KPU08YqerQW",
        "outputId": "33d5ccfa-eae0-4801-fd0c-8f1971cb1274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading MNIST dataset...\n",
            "Building AtA and AtY matrices in 12 batches...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1-1953166635.py:51: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 3 of 12\n",
            "Processed batch 6 of 12\n",
            "Processed batch 9 of 12\n",
            "Processed batch 12 of 12\n",
            "Solving ridge regression system...\n",
            "Training completed in 245.83 seconds.\n",
            "Testing completed in 1.88 seconds.\n",
            "Test accuracy: 96.24%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "#Hyperparameters\n",
        "N_GROUPS = 10              #Number of feature groups\n",
        "N_NODES = 10               #Feature nodes per group\n",
        "N_ENHANCE = 11000          #Number of enhancement nodes\n",
        "LAMBDA = 1e-8              #Ridge regularization parameter\n",
        "BATCH_SIZE = 5000          #Mini-batch size for incremental matrix accumulation\n",
        "SEED = 0                   #Random seed for reproducibility\n",
        "DTYPE = np.float32         #Data type for arrays\n",
        "\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "#Load MNIST dataset\n",
        "print(\"Downloading MNIST dataset...\")\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "X = mnist.data.astype(DTYPE) / 255.0\n",
        "y = mnist.target.astype(np.int32)\n",
        "\n",
        "X.shape[0]\n",
        "X_train, X_test = X[:60000], X[60000:]\n",
        "y_train, y_test = y[:60000], y[60000:]\n",
        "\n",
        "#One-hot encoding of labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "Y_train = encoder.fit_transform(y_train.reshape(-1, 1)).astype(DTYPE)\n",
        "Y_test = encoder.transform(y_test.reshape(-1, 1)).astype(DTYPE)\n",
        "\n",
        "n_features = X_train.shape[1]\n",
        "n_classes = Y_train.shape[1]\n",
        "\n",
        "#Total feature nodes and combined feature+enhancement nodes\n",
        "F_TOTAL = N_GROUPS * N_NODES        #100 feature nodes\n",
        "A_COLS = F_TOTAL + N_ENHANCE        #Total input dimension after feature + enhancement\n",
        "\n",
        "#Initialize random weights and biases for feature and enhancement nodes\n",
        "W_e = rng.uniform(-1, 1, size=(n_features, F_TOTAL)).astype(DTYPE)\n",
        "b_e = rng.uniform(-1, 1, size=(1, F_TOTAL)).astype(DTYPE)\n",
        "\n",
        "W_h = rng.uniform(-1, 1, size=(F_TOTAL, N_ENHANCE)).astype(DTYPE)\n",
        "b_h = rng.uniform(-1, 1, size=(1, N_ENHANCE)).astype(DTYPE)\n",
        "\n",
        "def sigmoid(z):\n",
        "    #Numerically stable sigmoid function to reduce overflow warnings\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "#Incremental computation of AtA = AᵀA and AtY = AᵀY for ridge regression\n",
        "start_train = time.time()\n",
        "AtA = np.zeros((A_COLS, A_COLS), dtype=DTYPE)\n",
        "AtY = np.zeros((A_COLS, n_classes), dtype=DTYPE)\n",
        "\n",
        "n_batches = math.ceil(X_train.shape[0] / BATCH_SIZE)\n",
        "print(f\"Building AtA and AtY matrices in {n_batches} batches...\")\n",
        "\n",
        "for i in range(n_batches):\n",
        "    start_idx = i * BATCH_SIZE\n",
        "    end_idx = min((i + 1) * BATCH_SIZE, X_train.shape[0])\n",
        "    X_batch, Y_batch = X_train[start_idx:end_idx], Y_train[start_idx:end_idx]\n",
        "\n",
        "    #Compute feature nodes (linear transformation)\n",
        "    Z_batch = np.matmul(X_batch, W_e) + b_e\n",
        "\n",
        "    #Compute enhancement nodes (sigmoid activation)\n",
        "    H_batch = sigmoid(np.matmul(Z_batch, W_h) + b_h)\n",
        "\n",
        "    #Concatenate feature and enhancement nodes\n",
        "    A_batch = np.hstack([Z_batch, H_batch])\n",
        "\n",
        "    #Accumulate sums for ridge regression system\n",
        "    AtA += A_batch.T @ A_batch\n",
        "    AtY += A_batch.T @ Y_batch\n",
        "\n",
        "    if (i + 1) % 3 == 0 or (i + 1) == n_batches:\n",
        "        print(f\"Processed batch {i + 1} of {n_batches}\")\n",
        "\n",
        "#Solve ridge regression: (AtA + λI) W = AtY\n",
        "print(\"Solving ridge regression system...\")\n",
        "ridge_matrix = AtA + LAMBDA * np.identity(A_COLS, dtype=DTYPE)\n",
        "W_out = np.linalg.solve(ridge_matrix, AtY)\n",
        "\n",
        "print(f\"Training completed in {time.time() - start_train:.2f} seconds.\")\n",
        "\n",
        "#Inference on test set (batched)\n",
        "start_test = time.time()\n",
        "y_pred_batches = []\n",
        "\n",
        "n_test_batches = math.ceil(X_test.shape[0] / BATCH_SIZE)\n",
        "for i in range(n_test_batches):\n",
        "    start_idx = i * BATCH_SIZE\n",
        "    end_idx = min((i + 1) * BATCH_SIZE, X_test.shape[0])\n",
        "\n",
        "    Z_test = np.matmul(X_test[start_idx:end_idx], W_e) + b_e\n",
        "    H_test = sigmoid(np.matmul(Z_test, W_h) + b_h)\n",
        "    A_test = np.hstack([Z_test, H_test])\n",
        "\n",
        "    y_pred_batches.append(A_test @ W_out)\n",
        "\n",
        "y_pred = np.vstack(y_pred_batches)\n",
        "\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "print(f\"Testing completed in {time.time() - start_test:.2f} seconds.\")\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaaPgSJ8gofm"
      },
      "source": [
        "# BREAST CANCER DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC5nWL41Z5jT",
        "outputId": "53965555-6bb4-45b2-b5e6-5dc2491e695a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Breast Cancer dataset...\n",
            "Starting training...\n",
            "Solving output weights...\n",
            "Training done in 0.003621 seconds\n",
            "Testing...\n",
            "Test done in 0.001937 seconds\n",
            "Test Accuracy: 97.66%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "# Hyperparameters\n",
        "n_groups = 2\n",
        "nodes_per_group = 8\n",
        "n_enhance = 4\n",
        "reg_lambda = 1e-6\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading Breast Cancer dataset...\")\n",
        "data = load_breast_cancer()\n",
        "X = data.data.astype(np.float32)\n",
        "y = data.target\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# One-hot encode labels\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "Y = encoder.fit_transform(y.reshape(-1, 1)).astype(np.float32)\n",
        "\n",
        "# Split into train/test (70/30)\n",
        "split = int(len(X) * 0.7)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "Y_train, Y_test = Y[:split], Y[split:]\n",
        "\n",
        "# Feature setup\n",
        "n_features = X_train.shape[1]\n",
        "n_classes = Y_train.shape[1]\n",
        "total_feat_nodes = n_groups * nodes_per_group\n",
        "input_dim = total_feat_nodes + n_enhance\n",
        "\n",
        "# Random weights and biases\n",
        "W_feat = np.random.uniform(-1, 1, (n_features, total_feat_nodes)).astype(np.float32)\n",
        "b_feat = np.random.uniform(-1, 1, (1, total_feat_nodes)).astype(np.float32)\n",
        "\n",
        "W_enh = np.random.uniform(-1, 1, (total_feat_nodes, n_enhance)).astype(np.float32)\n",
        "b_enh = np.random.uniform(-1, 1, (1, n_enhance)).astype(np.float32)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Train: Compute full A, then AᵀA and AᵀY\n",
        "print(\"Starting training...\")\n",
        "start = time.perf_counter()\n",
        "\n",
        "Z_train = X_train @ W_feat + b_feat\n",
        "H_train = sigmoid(Z_train @ W_enh + b_enh)\n",
        "A_train = np.hstack((Z_train, H_train))\n",
        "\n",
        "AtA = A_train.T @ A_train\n",
        "AtY = A_train.T @ Y_train\n",
        "\n",
        "# Solve ridge regression\n",
        "print(\"Solving output weights...\")\n",
        "ridge = AtA + reg_lambda * np.eye(input_dim)\n",
        "W_out = np.linalg.solve(ridge, AtY)\n",
        "\n",
        "print(f\"Training done in {time.perf_counter() - start:.6f} seconds\")\n",
        "\n",
        "# Test\n",
        "print(\"Testing...\")\n",
        "start_test = time.perf_counter()\n",
        "\n",
        "Z_test = X_test @ W_feat + b_feat\n",
        "H_test = sigmoid(Z_test @ W_enh + b_enh)\n",
        "A_test = np.hstack((Z_test, H_test))\n",
        "\n",
        "y_pred = A_test @ W_out\n",
        "acc = accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "\n",
        "print(f\"Test done in {time.perf_counter() - start_test:.6f} seconds\")\n",
        "print(f\"Test Accuracy: {acc * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}